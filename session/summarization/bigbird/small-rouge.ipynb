{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sentencepiece as spm\n",
    "\n",
    "vocab = '/home/husein/b2b/sp10m.cased.t5.model'\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(vocab)\n",
    "\n",
    "class Encoder:\n",
    "    def __init__(self, sp):\n",
    "        self.sp = sp\n",
    "        self.vocab_size = sp.GetPieceSize() + 100\n",
    "    \n",
    "    def encode(self, s):\n",
    "        return self.sp.EncodeAsIds(s)\n",
    "    \n",
    "    def decode(self, ids, strip_extraneous=False):\n",
    "        return self.sp.DecodeIds(list(ids))\n",
    "    \n",
    "encoder = Encoder(sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename):\n",
    "    with tf.gfile.GFile(frozen_graph_filename, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = load_graph('output/frozen_model.pb')\n",
    "x = g.get_tensor_by_name('import/Placeholder:0')\n",
    "top_p = g.get_tensor_by_name('import/top_p:0')\n",
    "temperature = g.get_tensor_by_name('import/temperature:0')\n",
    "logits = g.get_tensor_by_name('import/logits:0')\n",
    "test_sess = tf.Session(graph = g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://f000.backblazeb2.com/file/malay-dataset/testset/test-set-cnn.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/home/husein/b2b/test-set-cnn.json') as fopen:\n",
    "    test = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from unidecode import unidecode\n",
    "from malaya.text.rules import normalized_chars\n",
    "\n",
    "def filter_news(string):\n",
    "    string = string.lower()\n",
    "    return 'javascript is disabled' in string or 'requires javascript' in string or 'javascript' in string \\\n",
    "    or 'président' in string\n",
    "\n",
    "def make_cleaning(s, c_dict):\n",
    "    s = s.translate(c_dict)\n",
    "    return s\n",
    "\n",
    "def transformer_textcleaning(string):\n",
    "    \"\"\"\n",
    "    use by any transformer model before tokenization\n",
    "    \"\"\"\n",
    "    string = unidecode(string)\n",
    "    string = ' '.join(\n",
    "        [make_cleaning(w, normalized_chars) for w in string.split()]\n",
    "    )\n",
    "    string = re.sub('\\(dot\\)', '.', string)\n",
    "    string = (\n",
    "        re.sub(re.findall(r'\\<a(.*?)\\>', string)[0], '', string)\n",
    "        if (len(re.findall(r'\\<a (.*?)\\>', string)) > 0)\n",
    "        and ('href' in re.findall(r'\\<a (.*?)\\>', string)[0])\n",
    "        else string\n",
    "    )\n",
    "    string = re.sub(\n",
    "        r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', ' ', string\n",
    "    )\n",
    "    string = string.replace('\\n', ' ')\n",
    "    string = re.sub(r'[ ]+', ' ', string).strip().split()\n",
    "    string = [w for w in string if w[0] != '@']\n",
    "    return ' '.join(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_sequences = tf.keras.preprocessing.sequence.pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 136/1000 [2:22:24<24:24:20, 101.69s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 10\n",
    "results = []\n",
    "for i in tqdm(range(0, len(test['X']), batch_size)):\n",
    "    batch_x = test['X'][i: i + batch_size]\n",
    "    batches = []\n",
    "    for b in batch_x:\n",
    "        encoded = encoder.encode(f'ringkasan: {transformer_textcleaning(b)}')\n",
    "        encoded = encoded[:2047] + [1] \n",
    "        batches.append(encoded)\n",
    "    batches = pad_sequences(batches, padding='post', maxlen = 2048)\n",
    "    g = test_sess.run(logits, feed_dict = {x:batches, top_p: 0.0, temperature: 0.0})\n",
    "    for b in g:\n",
    "        results.append(encoder.decode(b.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor2tensor.utils import rouge\n",
    "from tensorflow.keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "sp_model = spm.SentencePieceProcessor()\n",
    "sp_model.Load(vocab)\n",
    "\n",
    "def calculate_rouges(predicted, batch_y, n_size = 2):\n",
    "    batch_y = [sp_model.EncodeAsIds(row) for row in batch_y]\n",
    "    predicted = [sp_model.EncodeAsIds(row) for row in predicted]\n",
    "    maxlen = max(max(len(row) for row in batch_y), max(len(row) for row in predicted))\n",
    "    batch_y = sequence.pad_sequences(batch_y, padding = 'post', maxlen = maxlen)\n",
    "    predicted = sequence.pad_sequences(predicted, padding = 'post', maxlen = maxlen)\n",
    "    \n",
    "    non = np.count_nonzero(batch_y, axis = 1)\n",
    "    o = []\n",
    "    for n in non:\n",
    "        o.append([True for _ in range(n)])\n",
    "    b = sequence.pad_sequences(o, dtype = np.bool, padding = 'post', value = False, maxlen = maxlen)\n",
    "    rouges = []\n",
    "    for i in range(b.shape[0]):\n",
    "        a = batch_y[i][b[i]]\n",
    "        p = predicted[i][b[i]]\n",
    "        score = rouge.rouge_n([a], [p], n = n_size)\n",
    "        rouges.append(score)\n",
    "    return np.mean(rouges)\n",
    "\n",
    "def calculate_rouge_l(predicted, batch_y):\n",
    "    batch_y = [sp_model.EncodeAsIds(row) for row in batch_y]\n",
    "    predicted = [sp_model.EncodeAsIds(row) for row in predicted]\n",
    "    maxlen = max(max(len(row) for row in batch_y), max(len(row) for row in predicted))\n",
    "    batch_y = sequence.pad_sequences(batch_y, padding = 'post', maxlen = maxlen)\n",
    "    predicted = sequence.pad_sequences(predicted, padding = 'post', maxlen = maxlen)\n",
    "    \n",
    "    non = np.count_nonzero(batch_y, axis = 1)\n",
    "    o = []\n",
    "    for n in non:\n",
    "        o.append([True for _ in range(n)])\n",
    "    b = sequence.pad_sequences(o, dtype = np.bool, padding = 'post', value = False, maxlen = maxlen)\n",
    "    rouges = []\n",
    "    for i in range(b.shape[0]):\n",
    "        a = batch_y[i][b[i]]\n",
    "        p = predicted[i][b[i]]\n",
    "        score = rouge.rouge_l_sentence_level([a], [p])\n",
    "        rouges.append(score)\n",
    "    return np.mean(rouges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27545756"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_rouges(results, test['Y'][:len(results)], n_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08543168"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_rouges(results, test['Y'][:len(results)], n_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18890981"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_rouge_l(results, test['Y'][:len(results)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
